{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f0ip2WksaKq",
        "outputId": "183d99f4-c151-4b11-e9ec-da45ec9e9957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Using cached openai-1.3.5-py3-none-any.whl (220 kB)\n",
            "Collecting httpx<1,>=0.23.0\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm>4\n",
            "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "Collecting typing-extensions<5,>=4.5\n",
            "  Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Collecting anyio<4,>=3.5.0\n",
            "  Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "Collecting distro<2,>=1.7.0\n",
            "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
            "Collecting pydantic<3,>=1.9.0\n",
            "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in ./myenv/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Collecting sniffio>=1.1\n",
            "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting idna>=2.8\n",
            "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi\n",
            "  Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.5/162.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.*\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Collecting pydantic-core==2.14.5\n",
            "  Downloading pydantic_core-2.14.5-cp310-cp310-macosx_11_0_arm64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting annotated-types>=0.4.0\n",
            "  Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: typing-extensions, tqdm, sniffio, idna, h11, distro, certifi, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
            "Successfully installed annotated-types-0.6.0 anyio-3.7.1 certifi-2023.11.17 distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 idna-3.6 openai-1.3.5 pydantic-2.5.2 pydantic-core-2.14.5 sniffio-1.3.0 tqdm-4.66.1 typing-extensions-4.8.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVSEk4MlsaNk",
        "outputId": "59c5cd11-9ed3-4033-8a08-6ba5b60c127b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai-whisper\n",
            "  Using cached openai-whisper-20231117.tar.gz (798 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting torch\n",
            "  Using cached torch-2.1.1-cp310-none-macosx_11_0_arm64.whl (59.6 MB)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.2-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting more-itertools\n",
            "  Using cached more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
            "Collecting tiktoken\n",
            "  Using cached tiktoken-0.5.1-cp310-cp310-macosx_11_0_arm64.whl (924 kB)\n",
            "Requirement already satisfied: tqdm in ./myenv/lib/python3.10/site-packages (from openai-whisper) (4.66.1)\n",
            "Collecting numba\n",
            "  Using cached numba-0.58.1-cp310-cp310-macosx_11_0_arm64.whl (2.6 MB)\n",
            "Collecting llvmlite<0.42,>=0.41.0dev0\n",
            "  Using cached llvmlite-0.41.1-cp310-cp310-macosx_11_0_arm64.whl (28.8 MB)\n",
            "Collecting requests>=2.26.0\n",
            "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Collecting regex>=2022.1.18\n",
            "  Using cached regex-2023.10.3-cp310-cp310-macosx_11_0_arm64.whl (291 kB)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "Collecting jinja2\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting filelock\n",
            "  Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: typing-extensions in ./myenv/lib/python3.10/site-packages (from torch->openai-whisper) (4.8.0)\n",
            "Collecting networkx\n",
            "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "Collecting sympy\n",
            "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Using cached charset_normalizer-3.3.2-cp310-cp310-macosx_11_0_arm64.whl (120 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.11.17)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Using cached MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_universal2.whl (17 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801344 sha256=3332bac137882719ae42d59b2e712b267d993a427f6da748b9480ae401d38f9f\n",
            "  Stored in directory: /Users/aakashbhatnagar/Library/Caches/pip/wheels/2c/93/d7/c85634824f66214d905951a6e1ad2ecb53734d8e299cac340d\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: mpmath, urllib3, sympy, regex, numpy, networkx, more-itertools, MarkupSafe, llvmlite, fsspec, filelock, charset-normalizer, requests, numba, jinja2, torch, tiktoken, openai-whisper\n",
            "Successfully installed MarkupSafe-2.1.3 charset-normalizer-3.3.2 filelock-3.13.1 fsspec-2023.10.0 jinja2-3.1.2 llvmlite-0.41.1 more-itertools-10.1.0 mpmath-1.3.0 networkx-3.2.1 numba-0.58.1 numpy-1.26.2 openai-whisper-20231117 regex-2023.10.3 requests-2.31.0 sympy-1.12 tiktoken-0.5.1 torch-2.1.1 urllib3-2.1.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYGTh27jsddT",
        "outputId": "a4924db7-f67e-4202-857f-59b3c29e07c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [47.2 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,467 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:13 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,244 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,520 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,248 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,015 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,284 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,152 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [39.5 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,498 kB]\n",
            "Fetched 11.8 MB in 3s (3,625 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "38 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJiTYQlb-EH6",
        "outputId": "e1fa9617-fef9-493a-acbd-fc6d9fb48806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.7.1-py3-none-any.whl (16.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting altair<6.0,>=4.2.0\n",
            "  Using cached altair-5.1.2-py3-none-any.whl (516 kB)\n",
            "Collecting typer[all]<1.0,>=0.9\n",
            "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
            "Requirement already satisfied: requests~=2.0 in ./myenv/lib/python3.10/site-packages (from gradio) (2.31.0)\n",
            "Collecting orjson~=3.0\n",
            "  Using cached orjson-3.9.10-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (242 kB)\n",
            "Requirement already satisfied: numpy~=1.0 in ./myenv/lib/python3.10/site-packages (from gradio) (1.26.2)\n",
            "Collecting aiofiles<24.0,>=22.0\n",
            "  Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting pillow<11.0,>=8.0\n",
            "  Using cached Pillow-10.1.0-cp310-cp310-macosx_11_0_arm64.whl (3.3 MB)\n",
            "Collecting gradio-client==0.7.0\n",
            "  Using cached gradio_client-0.7.0-py3-none-any.whl (302 kB)\n",
            "Collecting pandas<3.0,>=1.0\n",
            "  Downloading pandas-2.1.3-cp310-cp310-macosx_11_0_arm64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Using cached python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "Collecting huggingface-hub>=0.14.0\n",
            "  Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "Collecting uvicorn>=0.14.0\n",
            "  Using cached uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "Collecting tomlkit==0.12.0\n",
            "  Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting ffmpy\n",
            "  Using cached ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting fastapi\n",
            "  Using cached fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in ./myenv/lib/python3.10/site-packages (from gradio) (2.5.2)\n",
            "Collecting semantic-version~=2.0\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting importlib-resources<7.0,>=1.3\n",
            "  Downloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in ./myenv/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in ./myenv/lib/python3.10/site-packages (from gradio) (4.8.0)\n",
            "Requirement already satisfied: packaging in ./myenv/lib/python3.10/site-packages (from gradio) (23.2)\n",
            "Collecting matplotlib~=3.0\n",
            "  Using cached matplotlib-3.8.2-cp310-cp310-macosx_11_0_arm64.whl (7.5 MB)\n",
            "Collecting pyyaml<7.0,>=5.0\n",
            "  Using cached PyYAML-6.0.1-cp310-cp310-macosx_11_0_arm64.whl (169 kB)\n",
            "Requirement already satisfied: httpx in ./myenv/lib/python3.10/site-packages (from gradio) (0.25.2)\n",
            "Collecting pydub\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: markupsafe~=2.0 in ./myenv/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: fsspec in ./myenv/lib/python3.10/site-packages (from gradio-client==0.7.0->gradio) (2023.10.0)\n",
            "Collecting websockets<12.0,>=10.0\n",
            "  Using cached websockets-11.0.3-cp310-cp310-macosx_11_0_arm64.whl (121 kB)\n",
            "Collecting jsonschema>=3.0\n",
            "  Downloading jsonschema-4.20.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting toolz\n",
            "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./myenv/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
            "Requirement already satisfied: filelock in ./myenv/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n",
            "Collecting cycler>=0.10\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting pyparsing>=2.3.1\n",
            "  Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.45.1-cp310-cp310-macosx_10_9_universal2.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in ./myenv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.2.0-cp310-cp310-macosx_11_0_arm64.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1\n",
            "  Using cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl (66 kB)\n",
            "Collecting tzdata>=2022.1\n",
            "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "Collecting pytz>=2020.1\n",
            "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in ./myenv/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.14.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in ./myenv/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.10/site-packages (from requests~=2.0->gradio) (2023.11.17)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.10/site-packages (from requests~=2.0->gradio) (2.1.0)\n",
            "Collecting click<9.0.0,>=7.1.1\n",
            "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting colorama<0.5.0,>=0.4.3\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting rich<14.0.0,>=10.11.0\n",
            "  Downloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h11>=0.8 in ./myenv/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Collecting starlette<0.28.0,>=0.27.0\n",
            "  Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in ./myenv/lib/python3.10/site-packages (from fastapi->gradio) (3.7.1)\n",
            "Requirement already satisfied: sniffio in ./myenv/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: httpcore==1.* in ./myenv/lib/python3.10/site-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: exceptiongroup in ./myenv/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.2.0)\n",
            "Collecting jsonschema-specifications>=2023.03.6\n",
            "  Downloading jsonschema_specifications-2023.11.1-py3-none-any.whl (17 kB)\n",
            "Collecting attrs>=22.2.0\n",
            "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "Collecting rpds-py>=0.7.1\n",
            "  Downloading rpds_py-0.13.1-cp310-cp310-macosx_11_0_arm64.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.0/327.0 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting referencing>=0.28.4\n",
            "  Downloading referencing-0.31.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./myenv/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.17.2)\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: pytz, pydub, ffmpy, websockets, tzdata, toolz, tomlkit, shellingham, semantic-version, rpds-py, pyyaml, python-multipart, pyparsing, pillow, orjson, mdurl, kiwisolver, importlib-resources, fonttools, cycler, contourpy, colorama, click, attrs, aiofiles, uvicorn, typer, starlette, referencing, pandas, matplotlib, markdown-it-py, huggingface-hub, rich, jsonschema-specifications, gradio-client, fastapi, jsonschema, altair, gradio\n",
            "\u001b[33m  DEPRECATION: ffmpy is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py install for ffmpy ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed aiofiles-23.2.1 altair-5.1.2 attrs-23.1.0 click-8.1.7 colorama-0.4.6 contourpy-1.2.0 cycler-0.12.1 fastapi-0.104.1 ffmpy-0.3.1 fonttools-4.45.1 gradio-4.7.1 gradio-client-0.7.0 huggingface-hub-0.19.4 importlib-resources-6.1.1 jsonschema-4.20.0 jsonschema-specifications-2023.11.1 kiwisolver-1.4.5 markdown-it-py-3.0.0 matplotlib-3.8.2 mdurl-0.1.2 orjson-3.9.10 pandas-2.1.3 pillow-10.1.0 pydub-0.25.1 pyparsing-3.1.1 python-multipart-0.0.6 pytz-2023.3.post1 pyyaml-6.0.1 referencing-0.31.0 rich-13.7.0 rpds-py-0.13.1 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.27.0 tomlkit-0.12.0 toolz-0.12.0 typer-0.9.0 tzdata-2023.3 uvicorn-0.24.0.post1 websockets-11.0.3\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting moviepy\n",
            "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting decorator<5.0,>=4.0.2\n",
            "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in ./myenv/lib/python3.10/site-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in ./myenv/lib/python3.10/site-packages (from moviepy) (2.31.0)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in ./myenv/lib/python3.10/site-packages (from moviepy) (1.26.2)\n",
            "Collecting imageio<3.0,>=2.5\n",
            "  Downloading imageio-2.33.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio_ffmpeg>=0.2.0\n",
            "  Downloading imageio-ffmpeg-0.4.9.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: pillow>=8.3.2 in ./myenv/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (10.1.0)\n",
            "Requirement already satisfied: setuptools in ./myenv/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (65.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.11.17)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.1.0)\n",
            "Installing collected packages: proglog, imageio_ffmpeg, imageio, decorator, moviepy\n",
            "\u001b[33m  DEPRECATION: imageio_ffmpeg is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py install for imageio_ffmpeg ... \u001b[?25ldone\n",
            "\u001b[?25h  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 5.1.1\n",
            "    Uninstalling decorator-5.1.1:\n",
            "      Successfully uninstalled decorator-5.1.1\n",
            "\u001b[33m  DEPRECATION: moviepy is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py install for moviepy ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed decorator-4.4.2 imageio-2.33.0 imageio_ffmpeg-0.4.9 moviepy-1.0.3 proglog-0.1.10\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3ZrCX53_ssHy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aakashbhatnagar/Documents/masters/spark/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import cv2\n",
        "import os\n",
        "import urllib.request\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "import moviepy.editor as mp\n",
        "import json\n",
        "import re\n",
        "import gradio as gr\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmWMJ_FeJDyD"
      },
      "source": [
        "# Full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMDeEOwLtGYN"
      },
      "outputs": [],
      "source": [
        "def video_transcription(video_path):\n",
        "  try:\n",
        "    model = whisper.load_model('tiny')\n",
        "    transcript = model.transcribe(video_path, verbose = False, language = 'en')\n",
        "\n",
        "    # JSON Dump (Find a way to not create a file and just dump into a variable or something)\n",
        "    #json_file_path = video_path.split('/')[-1][:-4]+ \".json\"\n",
        "    #with open(json_file_path, 'w') as json_file:\n",
        "    #json.dump(transcript, json_file, indent = 2)\n",
        "    #json_file_path = video_path.split('/')[-1][:-4]+ \".json\"\n",
        "    #with open(json_file_path, 'w') as json_file:\n",
        "    return json.dumps(transcript)\n",
        "\n",
        "  except Exception as e:\n",
        "    return e\n",
        "\n",
        "def action_detection(transcript, openai_key=\"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\"):\n",
        "  try:\n",
        "    # JSON Dump (Find a way to not create a file and just dump into a variable or something)\n",
        "    # with open(json_path, 'r') as f:\n",
        "    #  transcript = json.load(f)\n",
        "    transcript_string = ''\n",
        "    for segments in transcript['segments']:\n",
        "      transcript_string+=str(segments['id'])+str(segments['text']+'\\n')\n",
        "\n",
        "    client = OpenAI(api_key = openai_key)\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "      model=\"gpt-4-1106-preview\",\n",
        "      # messages=[\n",
        "      #   {\"role\": \"system\", \"content\": f\"Given this {transcript_string} You are an AI system specialized in detecting planning issues, critiquing plans, and analyzing conversations between people regarding how to disperse. Additionally, identify any instances suggesting 1st Amendment violations or officers expressing the belief that this protest was anti-police. Finally, flag any aggressive comments found in the audio transcript.\"},\n",
        "      #   {\"role\": \"user\", \"content\":\"Give responce like this following examples: Sentence: '18: What do you got?' Explanation: This sentence may indicate confusion or a need for clarification, as the speaker is asking for information. It could potentially be a planning issue if the speaker is seeking information to execute a specific task.\"}\n",
        "      # ]\n",
        "\n",
        "      messages=[\n",
        "        {\"role\": \"user\", \"content\": f\"You are an AI system specialized in detecting planning issues, critiquing plans, and analyzing conversations between police officers regarding how to disperse. Additionally, identify any instances suggesting 1st Amendment violations, criticizing the lack of a plan, and aggressive comments. Transcript:\\n\\n{transcript_string}\\n\\n\"},\n",
        "        {\"role\": \"user\", \"content\": \"Give response only in the json format for example: \\{\\\"1\\\":  \\\"What should we do now. I don't have a clue?\\\", \\\"2\\\": \\\"what the fuck is this\\\", \\\"3\\\":\\\"Beat the fuck out of them\\\"\\}. There can be multiple instances, find out all of them. If you do not find anything just return {\\\"None\\\":\\\"None\\\"}\"}\n",
        "      ]\n",
        "    )\n",
        "\n",
        "\n",
        "    output = completion.choices[0].message.content\n",
        "\n",
        "    # paragraphs = re.split(r'\\n\\n', output)\n",
        "\n",
        "    # sentences = []\n",
        "    # explanations = []\n",
        "\n",
        "    # for paragraph in paragraphs:\n",
        "    #     sentence_match = re.search(r\"Sentence: '(.+)'\", paragraph)\n",
        "    #     explanation_match = re.search(r\"Explanation: (.+)\", paragraph)\n",
        "\n",
        "    #     if sentence_match and explanation_match:\n",
        "    #         sentences.append(sentence_match.group(1).split(': ')[-1])\n",
        "    #         explanations.append(explanation_match.group(1))\n",
        "\n",
        "    # #for i in range(len(sentences)):\n",
        "    # #    print(f\"Sentence: '{sentences[i]}'\")\n",
        "    # #    print(f\"Explanation: {explanations[i]}\\n\")\n",
        "\n",
        "    # for sentence_to_search in sentences:\n",
        "    #     pattern = re.compile(re.escape(sentence_to_search), re.IGNORECASE)\n",
        "\n",
        "    #     matching_entries = [entry for entry in transcript['segments'] if re.search(pattern, entry['text'])]\n",
        "\n",
        "    #     sent_with_time = []\n",
        "    #     if matching_entries:\n",
        "    #         for entry in matching_entries:\n",
        "    #             sent_with_time.append(sentence_to_search + ' Start Time: ', str(entry['start']) + ' End Time: ', str(entry['end']))\n",
        "    \n",
        "    # output_dict = json.loads(output)\n",
        "\n",
        "    return output\n",
        "\n",
        "  except Exception as e:\n",
        "    return e\n",
        "\n",
        "def process_video(video_path, weights):\n",
        "    try:\n",
        "        # This code cell detects batons in the video\n",
        "        current_frame = 0\n",
        "        model = YOLO(weights)\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        conseq_frames = 0\n",
        "        start_time = \"\"\n",
        "        end_time = \"\"\n",
        "        res = []\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Detecting baton on one frame per second\n",
        "            if current_frame % fps == 0:\n",
        "                currect_sec = current_frame/fps\n",
        "\n",
        "                # Model prediction on current frame\n",
        "                results = model(frame, verbose = False)\n",
        "                count = 0\n",
        "                classes = results[0].boxes.data\n",
        "\n",
        "                # Formatting the time for printing\n",
        "                hours, remainder = divmod(currect_sec, 3600)\n",
        "                minutes, seconds = divmod(remainder, 60)\n",
        "                hours = str(int(hours)).zfill(2)\n",
        "                minutes = str(int(minutes)).zfill(2)\n",
        "                seconds = str(int(seconds)).zfill(2)\n",
        "\n",
        "                for i in classes:\n",
        "\n",
        "                   # Checking if baton is detected (i.e. if the class corresponding to baton is 1 or not)\n",
        "                    if float(i[5]) == 1:\n",
        "                        count+=1\n",
        "\n",
        "                # Marking the start_time if this is the first consecutive frame a baton is detected in\n",
        "                if count >= 1:\n",
        "                    conseq_frames+=1\n",
        "                    if conseq_frames == 1:\n",
        "                        start_time = hours + \":\" + minutes + \":\" + seconds\n",
        "\n",
        "                # Marking the end time if after one or multiple consecutive frames of detection, a baton is not detected\n",
        "                else:\n",
        "                    if conseq_frames > 0:\n",
        "                        conseq_frames = 0\n",
        "                        end_time = hours + \":\" + minutes + \":\" + seconds\n",
        "\n",
        "                        # Printing time intervals in which baton was detected\n",
        "                        res.append(start_time + \" to \" + end_time)\n",
        "                        start_time = \"\"\n",
        "                        end_time = \"\"\n",
        "\n",
        "            current_frame += 1\n",
        "        cap.release()\n",
        "\n",
        "        return \"\\n\".join(res)\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        return e\n",
        "\n",
        "def all_funcs(openai_key,video_path, yolo_weights, pr = gr.Progress(track_tqdm = True)):\n",
        "\n",
        "  video_path = video_path[0].split('/')[-1]\n",
        "  yolo_weights = yolo_weights[0].split('/')[-1]\n",
        "  transcript = video_transcription(video_path)\n",
        "  sentences = action_detection(json.loads(transcript), openai_key)\n",
        "  batons = process_video(video_path, yolo_weights)\n",
        "\n",
        "  print(\"ALL FUNC Executed without errors\")\n",
        "\n",
        "  return sentences, batons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "transcript = open(\"Civil_Unrest_Tremont_@_Winter-001.srt\").read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "out = action_detection(transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expecting value: line 1 column 1 (char 0)\n"
          ]
        }
      ],
      "source": [
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(transcript[:5000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'16': \"No, you've got to cut through them.\",\n",
              " '26': 'Fucking assholes.',\n",
              " '27': 'All of you.',\n",
              " '28': \"I fucking hate y'all.\",\n",
              " '32': \"You don't deserve to be here.\",\n",
              " '34': \"You don't deserve to be here.\",\n",
              " '36': \"You don't deserve any of those badges.\",\n",
              " '38': \"You don't deserve that badge.\",\n",
              " '40': \"You don't deserve your badge.\",\n",
              " '42': \"And you don't deserve your badge.\",\n",
              " '43': 'Fuck you.',\n",
              " '44': 'Fuck you.'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "json.loads(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'dict' and 'dict'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/aakashbhatnagar/Documents/masters/spark/Spark Deployment.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aakashbhatnagar/Documents/masters/spark/Spark%20Deployment.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m {\u001b[39m1\u001b[39;49m:\u001b[39m2\u001b[39;49m} \u001b[39m+\u001b[39;49m {\u001b[39m4\u001b[39;49m:\u001b[39m5\u001b[39;49m}\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'dict'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "ZbZKUNl3Mttf",
        "outputId": "6c0912aa-f2d3-49f7-db58-473905111653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ALL FUNC Executed without errors\n"
          ]
        }
      ],
      "source": [
        "btn = gr.Interface(\n",
        "    fn = all_funcs,\n",
        "    inputs = [\"text\", gr.Files(label = \"Select Video File\"), gr.Files(label = \"Select YOLOv8 Weights File\")],\n",
        "    outputs=[gr.Textbox(label = \"Audio Analysis Time Stamps\", lines = 20), gr.Textbox(label = \"Baton Detection Timestamps\", lines = 20)]\n",
        ")\n",
        "\n",
        "btn.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMF48OxVJHLp"
      },
      "source": [
        "# Baton Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VSlkVeNJQo4"
      },
      "outputs": [],
      "source": [
        "def process_video(video_path, weights):\n",
        "    try:\n",
        "        # This code cell detects batons in the video\n",
        "        current_frame = 0\n",
        "        model = YOLO(weights)\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        conseq_frames = 0\n",
        "        start_time = \"\"\n",
        "        end_time = \"\"\n",
        "        res = []\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Detecting baton on one frame per second\n",
        "            if current_frame % fps == 0:\n",
        "                currect_sec = current_frame/fps\n",
        "\n",
        "                # Model prediction on current frame\n",
        "                results = model(frame, verbose = False)\n",
        "                count = 0\n",
        "                classes = results[0].boxes.data\n",
        "\n",
        "                # Formatting the time for printing\n",
        "                hours, remainder = divmod(currect_sec, 3600)\n",
        "                minutes, seconds = divmod(remainder, 60)\n",
        "                hours = str(int(hours)).zfill(2)\n",
        "                minutes = str(int(minutes)).zfill(2)\n",
        "                seconds = str(int(seconds)).zfill(2)\n",
        "\n",
        "                for i in classes:\n",
        "\n",
        "                   # Checking if baton is detected (i.e. if the class corresponding to baton is 1 or not)\n",
        "                    if float(i[5]) == 1:\n",
        "                        count+=1\n",
        "\n",
        "                # Marking the start_time if this is the first consecutive frame a baton is detected in\n",
        "                if count >= 1:\n",
        "                    conseq_frames+=1\n",
        "                    if conseq_frames == 1:\n",
        "                        start_time = hours + \":\" + minutes + \":\" + seconds\n",
        "\n",
        "                # Marking the end time if after one or multiple consecutive frames of detection, a baton is not detected\n",
        "                else:\n",
        "                    if conseq_frames > 0:\n",
        "                        conseq_frames = 0\n",
        "                        end_time = hours + \":\" + minutes + \":\" + seconds\n",
        "\n",
        "                        # Printing time intervals in which baton was detected\n",
        "                        res.append(start_time + \" to \" + end_time)\n",
        "                        start_time = \"\"\n",
        "                        end_time = \"\"\n",
        "\n",
        "            current_frame += 1\n",
        "        cap.release()\n",
        "\n",
        "        return \"\\n\".join(res)\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        return e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "uSBK_3VBJQmC",
        "outputId": "a18e4eeb-6b99-46c0-99b6-ae3a6e68ae99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://06b7f8c10c60967e6b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://06b7f8c10c60967e6b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with gr.Blocks() as demo:\n",
        "\n",
        "    video_path = gr.Textbox(label = \"Enter Path to Video\")\n",
        "    #openai_keys = gr.Textbox(label = \"Enter your OpenAI Key\")\n",
        "    weights = gr.Textbox(label = \"Enter Path to YOLOv8 Weights\")\n",
        "    #sentences = gr.Textbox(label = \"Sentences Detected\")\n",
        "    batons = gr.Textbox(label = \"Batons Detected\")\n",
        "    btn = gr.Button(value = \"Process Video\")\n",
        "    btn.click(process_video, inputs = [video_path, weights], outputs = batons)\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iqdjv7QowrZW"
      },
      "outputs": [],
      "source": [
        "/content/drive/MyDrive/Spark Project/Test_Video.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9-4b-gfrbwa"
      },
      "outputs": [],
      "source": [
        "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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPh9wSJvwvAt"
      },
      "outputs": [],
      "source": [
        "/content/drive/MyDrive/Spark Project/Data (For YOLOv8 Training)/Option 3 - Roboflow (60 Images)/YOLOv8 Best Weights.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvuZJI3-LGOU"
      },
      "outputs": [],
      "source": [
        "process_video(\"/content/drive/MyDrive/Spark Project/Test_Video.mp4\", \"/content/drive/MyDrive/Spark Project/Data (For YOLOv8 Training)/Option 3 - Roboflow (60 Images)/YOLOv8 Best Weights.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7ZZYQp_tbN4"
      },
      "outputs": [],
      "source": [
        "a = video_transcription(\"/content/drive/MyDrive/Spark Project/Test_Video.mp4\")\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtv7izc3HQHP",
        "outputId": "d7fed4ac-3d97-4580-bd21-f698f84f9615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.214-py3-none-any.whl (645 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.5/645.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.214\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
