{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ellKhmnZMUi_",
        "ZT8hTVSnyneG",
        "Olr7urJiNxW6",
        "21s499xgMWIp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Boilerplate"
      ],
      "metadata": {
        "id": "ellKhmnZMUi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "boRGvVJyyEwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "GUyD7iXsvztU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai-whisper"
      ],
      "metadata": {
        "id": "FHCiT-Q7vz94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "id": "nnNgD9-kv60e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import cv2\n",
        "import os\n",
        "import urllib.request\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "import moviepy.editor as mp\n",
        "import json\n",
        "import re"
      ],
      "metadata": {
        "id": "A6_rFnKF4Cql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add path to video\n",
        "# For a quick test, use this 4-minute long video clip: https://drive.google.com/file/d/1ewLP2R6_41w_17hSjoP9TNwwVZBEkZ1_/view?usp=sharing\n",
        "\n",
        "video_path = input(\"Enter the path to the video: \")"
      ],
      "metadata": {
        "id": "FtLrUGnBMMiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Transcription"
      ],
      "metadata": {
        "id": "ZT8hTVSnyneG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model('large-v3')"
      ],
      "metadata": {
        "id": "iSVQ3KY3SH3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_to_text(path):\n",
        "  result = model.transcribe(path,verbose=True)\n",
        "  return result\n",
        "\n",
        "def transcript_to_string(transcript):\n",
        "    string = ''\n",
        "    for segments in transcript['segments']:\n",
        "      string+=str(segments['id'])+str(segments['text']+'\\n')\n",
        "    return string"
      ],
      "metadata": {
        "id": "tXCjS3BSMMvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = audio_to_text(video_path)"
      ],
      "metadata": {
        "id": "62DHpDoAQIVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_file_path = video_path.split('/')[-1][:-4]+ \".json\"\n",
        "\n",
        "# Save the JSON object to the file\n",
        "with open(json_file_path, 'w') as json_file:\n",
        "    json.dump(transcript, json_file, indent=2)\n",
        "\n",
        "print(f\"JSON data saved to: {json_file_path}\")"
      ],
      "metadata": {
        "id": "RgDcP9ntM9Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action Detection"
      ],
      "metadata": {
        "id": "Olr7urJiNxW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actions:\n",
        "\n",
        "1. Officers complain about the lack of a plan\n",
        "2. Officers fail to offer people with directions\n",
        "3. Officers direct aggressive comments at protestors"
      ],
      "metadata": {
        "id": "Rh0w3jwbVPfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.engine.training import input_ops\n",
        "OPENAI_API_KEY= input('Enter your API key here:')"
      ],
      "metadata": {
        "id": "FKlvWctRYHV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_transcript_from_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        transcript = file.read()\n",
        "    return transcript\n",
        "\n",
        "\n",
        "# Provide the path to your transcript file\n",
        "json_transcript_path = input('Enter json path: ')\n",
        "\n",
        "with open(json_transcript_path, 'r') as f:\n",
        "  transcript = json.load(f)\n",
        "transcript_string = transcript_to_string(transcript)\n"
      ],
      "metadata": {
        "id": "sWr1KS8jVccm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab461637-787b-483f-a4ca-d66837185af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter json path:/content/test_video.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key = OPENAI_API_KEY)\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": f\"Given this {transcript_string} You are an AI system specialized in detecting planning issues, critiquing plans, and analyzing conversations between people regarding how to disperse. Additionally, identify any instances suggesting 1st Amendment violations or officers expressing the belief that this protest was anti-police. Finally, flag any aggressive comments found in the audio transcript.\"},\n",
        "    {\"role\": \"user\", \"content\":\"Give responce like this following examples: Sentence: '18: What do you got?' Explanation: This sentence may indicate confusion or a need for clarification, as the speaker is asking for information. It could potentially be a planning issue if the speaker is seeking information to execute a specific task.\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "pXfx9Y2eblkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "1hLUV2Ubcqig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs = re.split(r'\\n\\n', output)\n",
        "\n",
        "# Initialize empty lists to store sentences and explanations\n",
        "sentences = []\n",
        "explanations = []\n",
        "\n",
        "# Iterate through each paragraph\n",
        "for paragraph in paragraphs:\n",
        "    # Use regular expressions to find sentences and explanations\n",
        "    sentence_match = re.search(r\"Sentence: '(.+)'\", paragraph)\n",
        "    explanation_match = re.search(r\"Explanation: (.+)\", paragraph)\n",
        "\n",
        "    # If both sentence and explanation are found, append them to the respective lists\n",
        "    if sentence_match and explanation_match:\n",
        "        sentences.append(sentence_match.group(1).split(': ')[-1])\n",
        "        explanations.append(explanation_match.group(1))\n",
        "\n",
        "# Print the results\n",
        "for i in range(len(sentences)):\n",
        "    print(f\"Sentence: '{sentences[i]}'\")\n",
        "    print(f\"Explanation: {explanations[i]}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96Ht35pTiccK",
        "outputId": "a143246c-f66b-4899-da95-387f3c8ea4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: 'GIMME 54.'\n",
            "Explanation: This sentence may indicate an urgent need for assistance, specifically a request for items or support. It could potentially be a planning issue if the speaker is trying to coordinate logistics or resources for a specific task.\n",
            "\n",
            "Sentence: 'What the fuck is this?'\n",
            "Explanation: This sentence may indicate confusion, frustration, or agitation, suggesting that the speaker is questioning the situation or circumstances. It could potentially be a planning issue if the speaker is uncertain about the plan of action or decision-making process.\n",
            "\n",
            "Sentence: 'Back up.'\n",
            "Explanation: This sentence may indicate a need to create physical space or establish order, possibly to facilitate movement or address overcrowding. It could potentially be a planning issue if the speaker is trying to implement a structural plan for organizing a physical space.\n",
            "\n",
            "Sentence: 'I'm armed civilian.'\n",
            "Explanation: This sentence may indicate the speaker's intent to communicate their armed status, potentially affecting the security or safety of the situation. It could potentially be a planning issue if the speaker is discussing security measures or safety protocols.\n",
            "\n",
            "Sentence: 'We're on our side. Right?'\n",
            "Explanation: This sentence may indicate a desire to confirm alignment or seek reassurance regarding a particular standpoint. It could potentially be a planning issue if the speaker is seeking collaboration, cooperation, or confirmation to execute a specific plan or strategy.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your list of dictionaries is named 'data'\n",
        "for sentence_to_search in sentences:\n",
        "    pattern = re.compile(re.escape(sentence_to_search), re.IGNORECASE)\n",
        "\n",
        "    matching_entries = [entry for entry in transcript['segments'] if re.search(pattern, entry['text'])]\n",
        "\n",
        "    if matching_entries:\n",
        "        for entry in matching_entries:\n",
        "            print(sentence_to_search, 'time start:', entry['start'],'time stop:', entry['end'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbxtPQaIlrez",
        "outputId": "68cc50e0-64f6-4239-d145-47149cf8f9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GIMME 54. time start: 737.96 time stop: 740.96\n",
            "What the fuck is this? time start: 544.0 time stop: 553.0\n",
            "Back up. time start: 614.0 time stop: 617.0\n",
            "Back up. time start: 619.0 time stop: 620.0\n",
            "Back up. time start: 625.0 time stop: 626.0\n",
            "Back up. time start: 1310.6 time stop: 1311.6\n",
            "Back up. time start: 1316.6 time stop: 1318.6\n",
            "Back up. time start: 1319.6 time stop: 1321.6\n",
            "Back up. time start: 7384.42 time stop: 7385.42\n",
            "I'm armed civilian. time start: 637.0 time stop: 639.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baton Detection"
      ],
      "metadata": {
        "id": "21s499xgMWIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 Model Fine-Tuned for detection of Police, Protestors, and Batons\n",
        "# Fine-Tuned Model Weights can be downloaded from here: https://drive.google.com/file/d/1IlKpRO27gYErr4NZvhfuTwyliRgKvc8m/view?usp=sharing\n",
        "\n",
        "model_path = input(\"Enter the path to the model weights: \")\n",
        "model = YOLO(model_path)"
      ],
      "metadata": {
        "id": "QDhS5_F2MQRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl_FFFwVK8TL"
      },
      "outputs": [],
      "source": [
        "# This code cell detects batons in the video\n",
        "\n",
        "current_frame = 0\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "conseq_frames = 0\n",
        "start_time = \"\"\n",
        "end_time = \"\"\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    # Detecting baton on one frame per second\n",
        "    if current_frame % fps == 0:\n",
        "      currect_sec = current_frame/fps\n",
        "\n",
        "      # Model prediction on current frame\n",
        "      results = model(frame, verbose = False)\n",
        "      count = 0\n",
        "      classes = results[0].boxes.data\n",
        "\n",
        "      # Formatting the time for printing\n",
        "      hours, remainder = divmod(currect_sec, 3600)\n",
        "      minutes, seconds = divmod(remainder, 60)\n",
        "      hours = str(int(hours)).zfill(2)\n",
        "      minutes = str(int(minutes)).zfill(2)\n",
        "      seconds = str(int(seconds)).zfill(2)\n",
        "\n",
        "      for i in classes:\n",
        "\n",
        "        # Checking if baton is detected (i.e. if the class corresponding to baton is 1 or not)\n",
        "        if float(i[5]) == 1:\n",
        "          count+=1\n",
        "\n",
        "      # Marking the start_time if this is the first consecutive frame a baton is detected in\n",
        "      if count >= 1:\n",
        "        conseq_frames+=1\n",
        "        if conseq_frames == 1:\n",
        "          start_time = hours + \":\" + minutes + \":\" + seconds\n",
        "\n",
        "      # Marking the end time if after one or multiple consecutive frames of detection, a baton is not detected\n",
        "      else:\n",
        "        if conseq_frames > 0:\n",
        "          conseq_frames = 0\n",
        "          end_time = hours + \":\" + minutes + \":\" + seconds\n",
        "\n",
        "          # Printing time intervals in which baton was detected\n",
        "          print(f\"Baton found from {start_time} to {end_time}\")\n",
        "          start_time = \"\"\n",
        "          end_time = \"\"\n",
        "\n",
        "    current_frame += 1\n",
        "\n",
        "cap.release()"
      ]
    }
  ]
}